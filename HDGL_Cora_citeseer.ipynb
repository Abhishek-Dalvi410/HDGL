{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following code is for HDGL which uses HD-Computing Operations. Clearly, Pytorch doesn't support operations such as Bit-wise Majority (For Bundling). This is why we translate 0/1 vectors to 1/-1 vectors as the Bundle Operator becomes signed addition in $\\{1,-1\\}^{\\beta}$ space. Similarly, Binding operator which is XOR operation in $\\{0,1\\}^{\\beta}$ space is the multiplication operation in the $\\{1,-1\\}^{\\beta}$ space.\n",
        "\n",
        "\n",
        "\n",
        "To summarize, below are the details for the bipolar counterparts:-\n",
        "\n",
        "\n",
        "*    Space: $\\{0,1\\}^{\\beta} \\longleftrightarrow \\{1,-1\\}^{\\beta}$\n",
        "*    Bit: $0 \\longleftrightarrow 1$\n",
        "\n",
        "*    Bit: $1 \\longleftrightarrow -1$\n",
        "*    Bundle: Bitwise Majority $\\longleftrightarrow$ Signed Addition\n",
        "\n",
        "*    Binding: XOR $\\longleftrightarrow$ Multiplication"
      ],
      "metadata": {
        "id": "EoPPrRY0VyLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now describe the pseudo-code to make things easier:-\n",
        "\n",
        "Given:-\n",
        "*   feat (Features of N nodes)\n",
        "*   G (graph with adjacnency information for N nodes)\n",
        "*   Train_val_nodes (ids of train and val nodes)\n",
        "*   Test_nodes (ids of test nodes)\n",
        "*   Number_of_Labels\n",
        "*   Labels_train_val (Labels for train which are from index 0 to Number_of_Labels-1)\n",
        "\n",
        "\n",
        "\n",
        "Psuedo-code:\n",
        "Let β=20k\n",
        "1.   Create Bipolar HD-vectors for each Labels; stored as Labels_HD_Vectors (size= (Number_of_Labels, 20k))\n",
        "2.   Project feat to $\\{-1,1\\}^{20k}$ space using RHPT to obtain feat_hashed.\n",
        "3.   Convert feat_hashed to bipolar vectors.\n",
        "4.   For i in train_and_validation nodes:-\n",
        "       *   Sample 9 1-hop Neighbors of i\n",
        "       *   Sample 21 2-hop Neighbors of i\n",
        "       *   r_i = feat_hashed[i],\n",
        "       *   R_1hop = Bundle(feat_hashed[1-hop_neighbors])\n",
        "       *   R_2hop = Bundle(feat_hashed[2-hop_neighbors])\n",
        "       *   z_i = Bind(r_i, R_1hop, R_2hop)\n",
        "       *   R_2hop = Bundle(feat_hashed[2-hop_neighbors])\n",
        "       *   z_i = Bind(r_i, R_1hop, R_2hop)\n",
        "       *   y_i = Labels_train_val[i] # get the label of train node\n",
        "       *   Labels_HD_Vectors[y_i] = Labels_HD_Vectors[y_i] + z_i (additon part of Bundling)\n",
        "5.    Labels_HD_Vectors = sign(Labels_HD_Vectors) # Bundle is complete\n",
        "-------------------Train Part Ends Here-----------------\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Now For Testing....\n",
        "1.   For i in test nodes:-\n",
        "       *   Sample 11 1-hop Neighbors of i\n",
        "       *   Sample 21 2-hop Neighbors of i\n",
        "       *   r_i = feat_hashed[i],\n",
        "       *   R_1hop = Bundle(feat_hashed[1-hop_neighbors])\n",
        "       *   R_2hop = Bundle(feat_hashed[2-hop_neighbors])\n",
        "       *   z_i = Bind(r_i, R_1hop, R_2hop)\n",
        "       *   R_2hop = Bundle(feat_hashed[2-hop_neighbors])\n",
        "       *   z_i = Bind(r_i, R_1hop, R_2hop)\n",
        "       *   y_prediction_i = Find_index_nearest_neighbor of z_i ( Labels_HD_Vectors[0], Labels_HD_Vectors[1], ... )\n",
        "       \n"
      ],
      "metadata": {
        "id": "PCDgIjf3V2RI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UshQaQBmJR6M",
        "outputId": "45ab842a-87b1-4bae-86ba-fb256dd9389b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
            "Wall time: 4.53 µs\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSxxTBZrb3gc",
        "outputId": "1c5e7e9c-5e64-46e9-c645-5b37bc9d73ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCWSkVfxK26f",
        "outputId": "fcd2ce1d-4393-4322-a3b0-796e737df30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl\n",
        "import os\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLA-MlAWeszP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import scipy\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.sparse import coo_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1QX4XomfzW2"
      },
      "outputs": [],
      "source": [
        "class HDGL_utils_functions():\n",
        "\n",
        "  def __init__(self, features_dimension, hash_length):\n",
        "    self.random_A = torch.randn(features_dimension, hash_length)\n",
        "    low = -2\n",
        "    high = 2\n",
        "    self.lmbda = (high - low) * torch.rand(hash_length) + low\n",
        "\n",
        "    print(\"Here\")\n",
        "\n",
        "  def get_ids_labels(self, train_nodes_mask, val_nodes_mask, test_nodes_mask, labels_for_nodes):\n",
        "\n",
        "    train_node_ids = torch.nonzero(train_nodes_mask).flatten()\n",
        "    val_node_ids = torch.nonzero(val_nodes_mask).flatten()\n",
        "    test_node_ids = torch.nonzero(test_nodes_mask).flatten()\n",
        "\n",
        "    train_node_labels = labels_for_nodes[train_node_ids]\n",
        "    val_node_labels = labels_for_nodes[val_node_ids]\n",
        "    test_node_labels= labels_for_nodes[test_node_ids]\n",
        "\n",
        "    return train_node_ids, train_node_labels, val_node_ids, val_node_labels, test_node_ids, test_node_labels\n",
        "\n",
        "  def create_hash(self, features):\n",
        "    r = torch.sparse.mm(features, self.random_A)\n",
        "    r = r + self.lmbda\n",
        "    r = (r > 0).float()\n",
        "    r = self.convert_binary_to_bipolar(r)\n",
        "    return r\n",
        "\n",
        "  def convert_binary_to_bipolar(self, HD_vecs):\n",
        "    return (2 * HD_vecs) -1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run experiments on different dataset, change below"
      ],
      "metadata": {
        "id": "bCW7fd1sWA4V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSdLxd8A8YmS",
        "outputId": "877a54fc-6fdb-43d7-96ed-854d2a2f95e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "7\n",
            "Number of classes:- tensor([0, 1, 2, 3, 4, 5, 6])\n",
            "Features dimension:- 1433\n",
            "Here\n"
          ]
        }
      ],
      "source": [
        "from dgl.data import CoraGraphDataset, CiteseerGraphDataset\n",
        "dataset = CoraGraphDataset() # change here\n",
        "num_classes = dataset.num_classes\n",
        "print(num_classes)\n",
        "g = dataset[0]\n",
        "\n",
        "# get data split\n",
        "train_mask = g.ndata['train_mask']\n",
        "val_mask = g.ndata['val_mask']\n",
        "test_mask = g.ndata['test_mask']\n",
        "\n",
        "# get labels\n",
        "labels = g.ndata['label']\n",
        "feat = g.ndata['feat']\n",
        "\n",
        "\n",
        "\n",
        "#---------------row normalzie\n",
        "row_sum = torch.sum(feat, dim=1, keepdim=True)\n",
        "\n",
        "# Avoid division by zero by adding a small epsilon\n",
        "epsilon = 1e-8\n",
        "row_sum = torch.where(row_sum == 0, torch.tensor(epsilon, dtype=row_sum.dtype, device=row_sum.device), row_sum)\n",
        "\n",
        "# Normalize each row by dividing by its sum\n",
        "normalized_features = feat / row_sum\n",
        "feat = normalized_features\n",
        "\n",
        "#---------------row normalzie end\n",
        "\n",
        "print(\"Number of classes:-\", torch.unique(labels))\n",
        "print(\"Features dimension:-\", feat.size()[1])\n",
        "\n",
        "HDC_helper = HDGL_utils_functions(features_dimension =  feat.size()[1], hash_length=50000)\n",
        "Labels_HD_Vectors = torch.randint(0, 2, size=(num_classes,50000))\n",
        "Labels_HD_Vectors = HDC_helper.convert_binary_to_bipolar(Labels_HD_Vectors)\n",
        "\n",
        "mask_Labels =  torch.randint(0, 2, size=Labels_HD_Vectors.size())\n",
        "mask_Labels = HDC_helper.convert_binary_to_bipolar(mask_Labels)\n",
        "mask_Labels = mask_Labels * 0.1\n",
        "\n",
        "train_node_ids, train_node_labels, val_node_ids, val_node_labels, test_node_ids, test_node_labels = HDC_helper.get_ids_labels(train_mask, val_mask, test_mask, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Learning begins here\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zZxT5h4YW10C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "start_time = time.time()\n",
        "###########################\n",
        "feat = HDC_helper.create_hash(feat.to_sparse()) # Mapping features to HD-space using RHPT\n",
        "###################\n",
        "print(\"Mapping raw features to HD space done\")\n",
        "#####################\n",
        "print(\"Starting to calculate HD latent representaion for nodes in the train/val set and creating Label HD Vectors\")\n",
        "###########################\n",
        "sampled_neighbors = {}\n",
        "g_2hop = dgl.transforms.khop_graph(g, 2)\n",
        "train_val_nodes = torch.cat((train_node_ids, val_node_ids))\n",
        "train_val_labels = torch.cat((train_node_labels, val_node_labels))\n",
        "for node, node_label_1 in zip(train_val_nodes,train_val_labels):\n",
        "    # Get 1-hop neighbors\n",
        "    one_hop_neighbors = g.successors(node).numpy()\n",
        "\n",
        "    if len(one_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 11 1-hop neighbors (or all if there are fewer than 9)\n",
        "    sampled_one_hop = np.random.choice(one_hop_neighbors, size=11, replace=True)\n",
        "\n",
        "    # Get 2-hop neighbors\n",
        "    two_hop_neighbors = g_2hop.successors(node).numpy()\n",
        "\n",
        "    if len(two_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 21 2-hop neighbors (or all if there are fewer than 9)\n",
        "    sampled_two_hop = np.random.choice(two_hop_neighbors, size=21, replace=True)\n",
        "\n",
        "    N_1hop = sampled_one_hop.tolist()\n",
        "\n",
        "    N_2hop = sampled_two_hop.tolist()\n",
        "\n",
        "    r_i = torch.sum((torch.unsqueeze(feat[node],0)), axis=0)\n",
        "\n",
        "    R_1hop = torch.sum((feat[N_1hop]),axis=0)\n",
        "\n",
        "    R_2hop = torch.sum((feat[N_2hop]),axis=0)\n",
        "\n",
        "    R_1hop = torch.sign(R_1hop)\n",
        "    R_2hop = torch.sign(R_2hop)\n",
        "\n",
        "    R_1hop = torch.roll(R_1hop,-1) #rotate once\n",
        "    R_2hop = torch.roll(R_2hop,-2) #rotate twice\n",
        "\n",
        "    z_i = r_i * R_1hop * R_2hop\n",
        "\n",
        "    y_i = node_label_1\n",
        "    Labels_HD_Vectors[y_i.item()] = Labels_HD_Vectors[y_i.item()] + z_i\n",
        "\n",
        "\n",
        "Labels_HD_Vectors = Labels_HD_Vectors + mask_Labels\n",
        "Labels_HD_Vectors = torch.sign(Labels_HD_Vectors)\n",
        "Labels_HD_Vectors = torch.where(Labels_HD_Vectors == -1, torch.tensor(0.0), torch.tensor(1.0)) # convert to binary\n",
        "\n",
        "###################\n",
        "end_time = time.time()\n",
        "elapsed_time_seconds = end_time - start_time\n",
        "print(\"Time Taken in Seconds\", elapsed_time_seconds)\n",
        "# Convert elapsed time to minutes\n",
        "elapsed_time_minutes = elapsed_time_seconds / 60\n",
        "print(\"Time Taken in Minutes\", elapsed_time_minutes)\n",
        "#####################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xahlm2upWXKJ",
        "outputId": "98adc50b-2166-498a-a889-39b309ee8dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping raw features to HD space done\n",
            "Starting to calculate HD latent representaion for nodes in the train/val set and creating Label HD Vectors\n",
            "Time Taken in Seconds 2.064880132675171\n",
            "Time Taken in Minutes 0.03441466887791952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Learning Phase Ends\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pyWx5ruWXrPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcuating latent HD representation for Test nodes and predicting labels"
      ],
      "metadata": {
        "id": "X5sBpL3dXx1t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLxV257BO755"
      },
      "outputs": [],
      "source": [
        "# Compute neighborrd for test nodes\n",
        "\n",
        "Test_nodes_label_preds = []\n",
        "for node in test_node_ids:\n",
        "    # Get 1-hop neighbors\n",
        "    one_hop_neighbors = g.successors(node).numpy()\n",
        "\n",
        "    if len(one_hop_neighbors) == 0: # No 1-hop neighbors for a test node then some default label\n",
        "      Test_nodes_label_preds.append(0)\n",
        "      continue\n",
        "\n",
        "    # Sample 11 1-hop neighbors (or all if there are fewer than 9)\n",
        "    sampled_one_hop = np.random.choice(one_hop_neighbors, size=11, replace=True)\n",
        "\n",
        "    # Get 2-hop neighbors\n",
        "    two_hop_neighbors = g_2hop.successors(node).numpy()\n",
        "\n",
        "    # Exclude node form 2 hop nodes\n",
        "    two_hop_neighbors = list(set(two_hop_neighbors))\n",
        "\n",
        "    # Sample 21 2-hop neighbors (or all if there are fewer than 9)\n",
        "    sampled_two_hop = np.random.choice(two_hop_neighbors, size=21, replace=True)\n",
        "\n",
        "\n",
        "    r_i = torch.sum((torch.unsqueeze(feat[node],0)), axis=0)\n",
        "\n",
        "    N_1hop = sampled_one_hop.tolist()\n",
        "    R_1hop = torch.sum((feat[N_1hop]),axis=0)\n",
        "\n",
        "    N_2hop = sampled_two_hop.tolist()\n",
        "    R_2hop = torch.sum((feat[N_2hop]),axis=0)\n",
        "\n",
        "    R_1hop = torch.sign(R_1hop)\n",
        "    R_2hop = torch.sign(R_2hop)\n",
        "\n",
        "    R_1hop = torch.roll(R_1hop,-1) #rotate once\n",
        "    R_2hop = torch.roll(R_2hop,-2) #rotate twice\n",
        "\n",
        "    z_i = r_i * R_1hop * R_2hop\n",
        "\n",
        "    z_i = torch.where(z_i == -1, torch.tensor(0.0), torch.tensor(1.0)) # convert to binary\n",
        "\n",
        "    Test_labels_pred_distances = torch.cdist(torch.unsqueeze(z_i,0), Labels_HD_Vectors, p=1)\n",
        "\n",
        "    y_i_pred = torch.argmin(Test_labels_pred_distances, dim=1)\n",
        "\n",
        "    Test_nodes_label_preds.append(y_i_pred.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Accuracy of the predictions"
      ],
      "metadata": {
        "id": "aVt-pLXAYXv4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGgyowb9EjLE",
        "outputId": "01a1c5d6-8253-47d7-ec00-3e66e1b67497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.797"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(test_node_labels.numpy(), Test_nodes_label_preds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ps9YqgDD31en"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}