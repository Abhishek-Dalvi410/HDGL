{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following code is for HDGL which uses HD-Computing Operations. Clearly, Pytorch doesn't support operations such as Bit-wise Majority (For Bundling). This is why we translate 0/1 vectors to 1/-1 vectors as the Bundle Operator becomes signed addition in $\\{1,-1\\}^{\\beta}$ space. Similarly, Binding operator which is XOR operation in $\\{0,1\\}^{\\beta}$ space is the multiplication operation in the $\\{1,-1\\}^{\\beta}$ space.\n",
        "\n",
        "\n",
        "\n",
        "To summarize, below are the details for the bipolar counterparts:-\n",
        "\n",
        "\n",
        "*    Space: $\\{0,1\\}^{\\beta} \\longleftrightarrow \\{1,-1\\}^{\\beta}$\n",
        "*    Bit: $0 \\longleftrightarrow 1$\n",
        "\n",
        "*    Bit: $1 \\longleftrightarrow -1$\n",
        "*    Bundle: Bitwise Majority $\\longleftrightarrow$ Signed Addition\n",
        "\n",
        "*    Binding: XOR $\\longleftrightarrow$ Multiplication"
      ],
      "metadata": {
        "id": "EoPPrRY0VyLl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UshQaQBmJR6M",
        "outputId": "393ab843-622d-4dc4-979b-2f3552d4c359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
            "Wall time: 3.81 µs\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSxxTBZrb3gc",
        "outputId": "b673662c-40a8-4e4f-ed7a-f0f8351f0fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch -y\n",
        "!pip uninstall torchvision -y\n",
        "!pip uninstall torchaudio -y\n",
        "!pip uninstall torchtext -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKAYHTW3hfXi",
        "outputId": "cdb0eed8-f25c-4b23-ac9e-eaebb1960762"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.0+cu121\n",
            "Uninstalling torch-2.5.0+cu121:\n",
            "  Successfully uninstalled torch-2.5.0+cu121\n",
            "Found existing installation: torchvision 0.20.0+cu121\n",
            "Uninstalling torchvision-0.20.0+cu121:\n",
            "  Successfully uninstalled torchvision-0.20.0+cu121\n",
            "Found existing installation: torchaudio 2.5.0+cu121\n",
            "Uninstalling torchaudio-2.5.0+cu121:\n",
            "  Successfully uninstalled torchaudio-2.5.0+cu121\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aasSd0m5jLAo",
        "outputId": "b752166b-fb0b-4936-88a9-621ad4c24ab2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4) (1.3.0)\n",
            "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.18 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.11 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9AJGAZzjl_x",
        "outputId": "806a220a-ba6f-46cc-e0ca-564dcebe823c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCWSkVfxK26f",
        "outputId": "78b18fc8-c3f7-4254-8df4-310ee04596f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/torch-2.4/cu121/dgl-2.4.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (355.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.9.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.6)\n",
            "Requirement already satisfied: torch<=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.6.77)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html\n",
        "import os\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "PLA-MlAWeszP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import scipy\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.sparse import coo_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "A1QX4XomfzW2"
      },
      "outputs": [],
      "source": [
        "class HDGL_utils_functions():\n",
        "\n",
        "  def __init__(self, features_dimension, hash_length):\n",
        "    self.random_A = torch.randn(features_dimension, hash_length)\n",
        "    low = -2\n",
        "    high = 2\n",
        "    self.lmbda = (high - low) * torch.rand(hash_length) + low\n",
        "\n",
        "    print(\"Here\")\n",
        "\n",
        "  def get_ids_labels(self, train_nodes_mask, val_nodes_mask, test_nodes_mask, labels_for_nodes):\n",
        "\n",
        "    train_node_ids = torch.nonzero(train_nodes_mask).flatten()\n",
        "    val_node_ids = torch.nonzero(val_nodes_mask).flatten()\n",
        "    test_node_ids = torch.nonzero(test_nodes_mask).flatten()\n",
        "\n",
        "    train_node_labels = labels_for_nodes[train_node_ids]\n",
        "    val_node_labels = labels_for_nodes[val_node_ids]\n",
        "    test_node_labels= labels_for_nodes[test_node_ids]\n",
        "\n",
        "    return train_node_ids, train_node_labels, val_node_ids, val_node_labels, test_node_ids, test_node_labels\n",
        "\n",
        "  def create_hash(self, features):\n",
        "    r = torch.sparse.mm(features, self.random_A)\n",
        "    r = r + self.lmbda\n",
        "    r = (r > 0).float()\n",
        "    r = self.convert_binary_to_bipolar(r)\n",
        "    return r\n",
        "\n",
        "  def convert_binary_to_bipolar(self, HD_vecs):\n",
        "    return (2 * HD_vecs) -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse as sp\n",
        "\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape\n",
        "\n",
        "def mask_test_edges(adj): # From Thomas KipF GAE implementation https://github.com/tkipf/gae/blob/master/gae/preprocessing.py\n",
        "    # Function to build test set with 10% positive links\n",
        "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
        "    # TODO: Clean up.\n",
        "\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "    # Check that diag is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    num_test = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val = int(np.floor(edges.shape[0] / 20.))\n",
        "\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], val_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], val_edges):\n",
        "            continue\n",
        "        if val_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    assert ~ismember(test_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges, train_edges)\n",
        "    assert ~ismember(test_edges, train_edges)\n",
        "    assert ~ismember(val_edges, test_edges)\n",
        "\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    # NOTE: these edge lists only contain single direction of edge!\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
      ],
      "metadata": {
        "id": "IoeuiFk4A9tS"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "\n",
        "def load_data(dataset):\n",
        "    # load the data: x, tx, allx, graph\n",
        "    names = ['x', 'tx', 'allx', 'graph']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(\"data/ind.{}.{}\".format(dataset, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    x, tx, allx, graph = tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    if dataset == 'citeseer':\n",
        "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "        # Find isolated nodes, add them as zero-vecs into the right position\n",
        "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "        tx = tx_extended\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "\n",
        "    return adj, features"
      ],
      "metadata": {
        "id": "zU7YgCFqPpsj"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run experiments on different dataset, change below"
      ],
      "metadata": {
        "id": "bCW7fd1sWA4V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSdLxd8A8YmS",
        "outputId": "9f496766-1dfc-427b-eb96-2b5b2526cca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-9c5632e39c61>:20: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  objects.append(pkl.load(f, encoding='latin1'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features dimension:- 1433\n",
            "Here\n"
          ]
        }
      ],
      "source": [
        "adj, feat = load_data(\"cora\")\n",
        "\n",
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "\n",
        "feat = torch.tensor(feat.toarray()).float()\n",
        "\n",
        "src, dst = np.nonzero(adj_orig.toarray())\n",
        "\n",
        "g = dgl.graph((src, dst))\n",
        "\n",
        "#--------Remove Test Edges from DGL Graph object\n",
        "for test_edge in test_edges:\n",
        "  g.remove_edges([test_edge[0], test_edge[1]])\n",
        "  g.remove_edges([test_edge[1], test_edge[0]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#---------------row normalzie\n",
        "row_sum = torch.sum(feat, dim=1, keepdim=True)\n",
        "# Avoid division by zero by adding a small epsilon\n",
        "epsilon = 1e-8\n",
        "row_sum = torch.where(row_sum == 0, torch.tensor(epsilon, dtype=row_sum.dtype, device=row_sum.device), row_sum)\n",
        "\n",
        "# Normalize each row by dividing by its sum\n",
        "normalized_features = feat / row_sum\n",
        "feat = normalized_features\n",
        "\n",
        "#---------------row normalzie end\n",
        "\n",
        "print(\"Features dimension:-\", feat.size()[1])\n",
        "\n",
        "HD_VEC_SIZE = 50000\n",
        "\n",
        "HDC_helper = HDGL_utils_functions(features_dimension =  feat.size()[1], hash_length=HD_VEC_SIZE) # Change 20k,50k here\n",
        "\n",
        "edge_hyper_vec =  torch.randint(0, 2, size=(1,HD_VEC_SIZE))[0]\n",
        "edge_hyper_vec = HDC_helper.convert_binary_to_bipolar(edge_hyper_vec)\n",
        "\n",
        "no_edge_hyper_vec =  torch.randint(0, 2, size=(1,HD_VEC_SIZE))[0]\n",
        "no_edge_hyper_vec = HDC_helper.convert_binary_to_bipolar(edge_hyper_vec)\n",
        "\n",
        "hd_embd_nodes = torch.zeros(g.number_of_nodes(), HD_VEC_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Learning begins here\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zZxT5h4YW10C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feat = HDC_helper.create_hash(feat.to_sparse()) # Mapping features to HD-space using RHPT\n",
        "\n",
        "sampled_neighbors = {}\n",
        "g_2hop = dgl.transforms.khop_graph(g, 2)\n",
        "\n",
        "\n",
        "for node_u, node_v in np.vstack((train_edges,val_edges)):\n",
        "    # Get 1-hop neighbors\n",
        "    one_hop_neighbors = g.successors(node_u).numpy()\n",
        "\n",
        "    if len(one_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 11 1-hop neighbors\n",
        "    sampled_one_hop = np.random.choice(one_hop_neighbors, size=11, replace=True)\n",
        "\n",
        "    # Get 2-hop neighbors\n",
        "    two_hop_neighbors = g_2hop.successors(node_u).numpy()\n",
        "\n",
        "    if len(two_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 21 2-hop neighbors\n",
        "    sampled_two_hop = np.random.choice(two_hop_neighbors, size=21, replace=True)\n",
        "\n",
        "    N_1hop = sampled_one_hop.tolist()\n",
        "\n",
        "    N_2hop = sampled_two_hop.tolist()\n",
        "\n",
        "    r_i = torch.sum((torch.unsqueeze(feat[node_u],0)), axis=0)\n",
        "\n",
        "    R_1hop = torch.sum((feat[N_1hop]),axis=0)\n",
        "\n",
        "    R_2hop = torch.sum((feat[N_2hop]),axis=0)\n",
        "\n",
        "    R_1hop = torch.sign(R_1hop)\n",
        "    R_2hop = torch.sign(R_2hop)\n",
        "\n",
        "    R_1hop = torch.roll(R_1hop,-1) #rotate once\n",
        "    R_2hop = torch.roll(R_2hop,-2) #rotate twice\n",
        "\n",
        "    z_u = r_i * R_1hop * R_2hop\n",
        "\n",
        "\n",
        "    one_hop_neighbors = g.successors(node_v).numpy()\n",
        "\n",
        "    if len(one_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 11 1-hop neighbors\n",
        "    sampled_one_hop = np.random.choice(one_hop_neighbors, size=11, replace=True)\n",
        "\n",
        "    # Get 2-hop neighbors\n",
        "    two_hop_neighbors = g_2hop.successors(node_v).numpy()\n",
        "\n",
        "    if len(two_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 21 2-hop neighbors\n",
        "    sampled_two_hop = np.random.choice(two_hop_neighbors, size=21, replace=True)\n",
        "\n",
        "    N_1hop = sampled_one_hop.tolist()\n",
        "\n",
        "    N_2hop = sampled_two_hop.tolist()\n",
        "\n",
        "    r_i = torch.sum((torch.unsqueeze(feat[node_v],0)), axis=0)\n",
        "\n",
        "    R_1hop = torch.sum((feat[N_1hop]),axis=0)\n",
        "\n",
        "    R_2hop = torch.sum((feat[N_2hop]),axis=0)\n",
        "\n",
        "    R_1hop = torch.sign(R_1hop)\n",
        "    R_2hop = torch.sign(R_2hop)\n",
        "\n",
        "    R_1hop = torch.roll(R_1hop,-1) #rotate once\n",
        "    R_2hop = torch.roll(R_2hop,-2) #rotate twice\n",
        "\n",
        "\n",
        "\n",
        "    z_v = r_i * R_1hop * R_2hop\n",
        "\n",
        "    hd_embd_nodes[node_u] = z_u\n",
        "    hd_embd_nodes[node_v] = z_v\n",
        "\n",
        "\n",
        "    edge_hyper_vec = edge_hyper_vec + torch.sign(z_u * z_v)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "edge_hyper_vec = torch.sign(edge_hyper_vec)\n"
      ],
      "metadata": {
        "id": "xahlm2upWXKJ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find indices of negative edges (0s)\n",
        "# negative_edges_indices = np.transpose(np.where(g.adjacency_matrix().to_dense() == 0))\n",
        "\n",
        "negative_edges_indices = np.transpose(np.where(adj_orig.toarray() == 0))\n",
        "\n",
        "# # Randomly select 100 negative edges\n",
        "selected_negative_edges_indices = negative_edges_indices[np.random.choice(len(negative_edges_indices), 100, replace=False)]\n",
        "val_edges_false.extend(selected_negative_edges_indices)"
      ],
      "metadata": {
        "id": "PH-N1SvjMAom"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sampled_neighbors = {}\n",
        "g_2hop = dgl.transforms.khop_graph(g, 2)\n",
        "\n",
        "\n",
        "for node_u, node_v in val_edges_false:\n",
        "    # Get 1-hop neighbors\n",
        "    one_hop_neighbors = g.successors(node_u).numpy()\n",
        "\n",
        "    if len(one_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 11 1-hop neighbors (or all if there are fewer than 9)\n",
        "    sampled_one_hop = np.random.choice(one_hop_neighbors, size=11, replace=True)\n",
        "\n",
        "    # Get 2-hop neighbors\n",
        "    two_hop_neighbors = g_2hop.successors(node_u).numpy()\n",
        "\n",
        "    if len(two_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 21 2-hop neighbors (or all if there are fewer than 9)\n",
        "    sampled_two_hop = np.random.choice(two_hop_neighbors, size=21, replace=True)\n",
        "\n",
        "    N_1hop = sampled_one_hop.tolist()\n",
        "\n",
        "    N_2hop = sampled_two_hop.tolist()\n",
        "\n",
        "    r_i = torch.sum((torch.unsqueeze(feat[node_u],0)), axis=0)\n",
        "\n",
        "    R_1hop = torch.sum((feat[N_1hop]),axis=0)\n",
        "\n",
        "    R_2hop = torch.sum((feat[N_2hop]),axis=0)\n",
        "\n",
        "    R_1hop = torch.sign(R_1hop)\n",
        "    R_2hop = torch.sign(R_2hop)\n",
        "\n",
        "    R_1hop = torch.roll(R_1hop,-1) #rotate once\n",
        "    R_2hop = torch.roll(R_2hop,-2) #rotate twice\n",
        "\n",
        "    z_u = r_i * R_1hop * R_2hop\n",
        "\n",
        "\n",
        "    one_hop_neighbors = g.successors(node_v).numpy()\n",
        "\n",
        "    if len(one_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 11 1-hop neighbors (or all if there are fewer than 9)\n",
        "    sampled_one_hop = np.random.choice(one_hop_neighbors, size=11, replace=True)\n",
        "\n",
        "    # Get 2-hop neighbors\n",
        "    two_hop_neighbors = g_2hop.successors(node_v).numpy()\n",
        "\n",
        "    if len(two_hop_neighbors) == 0:\n",
        "      continue\n",
        "\n",
        "    # Sample 21 2-hop neighbors (or all if there are fewer than 9)\n",
        "    sampled_two_hop = np.random.choice(two_hop_neighbors, size=21, replace=True)\n",
        "\n",
        "    N_1hop = sampled_one_hop.tolist()\n",
        "\n",
        "    N_2hop = sampled_two_hop.tolist()\n",
        "\n",
        "    r_i = torch.sum((torch.unsqueeze(feat[node_v],0)), axis=0)\n",
        "\n",
        "    R_1hop = torch.sum((feat[N_1hop]),axis=0)\n",
        "\n",
        "    R_2hop = torch.sum((feat[N_2hop]),axis=0)\n",
        "\n",
        "    R_1hop = torch.sign(R_1hop)\n",
        "    R_2hop = torch.sign(R_2hop)\n",
        "\n",
        "    R_1hop = torch.roll(R_1hop,-1) #rotate once\n",
        "    R_2hop = torch.roll(R_2hop,-2) #rotate twice\n",
        "\n",
        "\n",
        "\n",
        "    z_v = r_i * R_1hop * R_2hop\n",
        "\n",
        "    no_edge_hyper_vec = no_edge_hyper_vec + torch.sign(z_u * z_v)\n",
        "\n",
        "\n",
        "\n",
        "no_edge_hyper_vec = torch.sign(no_edge_hyper_vec)"
      ],
      "metadata": {
        "id": "NqCCi4-oyFlK"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_edge_v = hd_embd_nodes * edge_hyper_vec\n",
        "neg_edge_v = hd_embd_nodes * no_edge_hyper_vec\n",
        "\n",
        "\n",
        "adj_distances_pos = torch.cdist(pos_edge_v, hd_embd_nodes)/HD_VEC_SIZE\n",
        "adj_distances_neg = torch.cdist(neg_edge_v, hd_embd_nodes)/HD_VEC_SIZE\n",
        "\n",
        "\n",
        "adj_probs = torch.where(adj_distances_pos < adj_distances_neg, (1-adj_distances_pos) + adj_distances_neg, adj_distances_pos - (1 -adj_distances_neg))\n",
        "\n",
        "adj_prediction = torch.sigmoid(adj_probs)\n"
      ],
      "metadata": {
        "id": "9aWgHnW3J6fU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "def get_roc_score(edges_pos, edges_neg, adj_pred, adj_orig):\n",
        "    '''''\n",
        "    adj_pred is the reconstructed adjacency matrix\n",
        "    adj_orig is the original adjacency matrix\n",
        "    Get AUCROC score and AP score\n",
        "    This Function is based of Thomas Kipf VGAE implementation\n",
        "    (https://github.com/tkipf/gae/tree/master)\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append((adj_pred[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append((adj_pred[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "\n",
        "    return roc_score, ap_score"
      ],
      "metadata": {
        "id": "bY63C-OJIwkv"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_roc_score(test_edges, test_edges_false, adj_prediction.numpy(), adj_orig.toarray())"
      ],
      "metadata": {
        "id": "_4XlX_MwYOa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659e34ac-fb9c-43ec-dcb9-e458e9d1e9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8645226101703459, 0.8995520738047991)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_roc_score(test_edges, test_edges_false, adj_prediction.numpy(), adj_orig.toarray())"
      ],
      "metadata": {
        "id": "DPCbEypcZtPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3c1a95-67cf-4449-faeb-bc330b0b2e7a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8595969452235812, 0.8918983118997427)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMv_mQoTkSK8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}