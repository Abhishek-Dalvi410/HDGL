{"cells":[{"cell_type":"markdown","source":["To facilitate the execution of experiments on various datasets, modify the \"--dataset\" argument within the codebase. The initial implementation of SGC, which serves as the foundation for this code, can be found at the GitHub repository https://github.com/Tiiiger/SGC/tree/master.\n","\n","The Hyper-parameter Tuning of SGC is over 12 possible configurations which can be found in code.\n","\n","The current implementation downloads and loads the physics and CS dataset using DGL.\n","\n","For cora, citeseer and pubmed datasets, the loading of the dataset is same as the original implementation ; which uses \"data\" folder from the the OG implementation repo https://github.com/Tiiiger/SGC/tree/master."],"metadata":{"id":"gTEals2WGK9n"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALCPOkcHfCmh"},"outputs":[],"source":["import argparse\n","import torch\n","\n","def get_citation_args():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--no-cuda', action='store_true', default=False,\n","                        help='Disables CUDA training.')\n","    parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n","    parser.add_argument('--epochs', type=int, default=1000,\n","                        help='Number of epochs to train.')\n","    parser.add_argument('--lr', type=float, default=0.01,\n","                        help='Initial learning rate.')\n","    parser.add_argument('--weight_decay', type=float, default=5e-6,\n","                        help='Weight decay (L2 loss on parameters).')\n","    parser.add_argument('--hidden', type=int, default=0,\n","                        help='Number of hidden units.')\n","    parser.add_argument('--dropout', type=float, default=0,\n","                        help='Dropout rate (1 - keep probability).')\n","\n","    # cora, citeseer, pubmed, CS, Physics, BlogCatalog, DBLP\n","    parser.add_argument('--dataset', type=str, default=\"cora\",\n","                        help='Dataset to use.')\n","    parser.add_argument('--model', type=str, default=\"SGC\",\n","                        choices=[\"SGC\"],\n","                        help='model to use.')\n","    parser.add_argument('--feature', type=str, default=\"mul\",\n","                        choices=['mul', 'cat', 'adj'],\n","                        help='feature-type')\n","    parser.add_argument('--normalization', type=str, default='AugNormAdj',\n","                       choices=['AugNormAdj'],\n","                       help='Normalization method for the adjacency matrix.')\n","    parser.add_argument('--degree', type=int, default=2,\n","                        help='degree of the approximation.')\n","    parser.add_argument('--per', type=int, default=-1,\n","                        help='Number of each nodes so as to balance.')\n","    parser.add_argument('--experiment', type=str, default=\"base-experiment\",\n","                        help='feature-type')\n","    parser.add_argument('--tuned', action='store_true', help='use tuned hyperparams')\n","\n","    args, _ = parser.parse_known_args()\n","    args.cuda = not args.no_cuda and torch.cuda.is_available()\n","    return args"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gzfCGI1s8-9"},"outputs":[],"source":["def split_train_val_test_ids(labels, train_samples_per_class=20, val_samples_per_class=30):\n","    unique_labels = np.unique(labels)\n","\n","    train_ids = []\n","    val_ids = []\n","    test_ids = []\n","\n","    for label in unique_labels:\n","        # Get indices of samples with the current label\n","        label_indices = np.where(labels == label)[0]\n","\n","        # Shuffle the indices to randomize the samples\n","        np.random.shuffle(label_indices)\n","\n","        # Split the indices into train, val, and test sets\n","        train_indices = label_indices[:train_samples_per_class]\n","        val_indices = label_indices[train_samples_per_class:(train_samples_per_class + val_samples_per_class)]\n","        test_indices = label_indices[(train_samples_per_class + val_samples_per_class):]\n","\n","        train_ids.extend(train_indices)\n","        val_ids.extend(val_indices)\n","        test_ids.extend(test_indices)\n","\n","    return train_ids, val_ids, test_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBwJ3yPU0PZ8","executionInfo":{"status":"ok","timestamp":1715459792322,"user_tz":240,"elapsed":51712,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}},"outputId":"03db583e-2ba6-492f-82f1-b232303d93df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dgl\n","  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dgl\n","Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["!pip install dgl"]},{"cell_type":"code","source":["from dgl.data import DGLDataset\n","\n","class Blogcatalog(DGLDataset):\n","    def __init__(self):\n","        super().__init__(name=\"Blogcatalog\")\n","\n","    def process(self):\n","          print(\"Loading Blogcatalog graph dataset...\")\n","          data = np.load('blogcatalog.npz', allow_pickle=True)\n","          labels = data['node_label']\n","          feat = data['node_attr']\n","          adj_matrix =  data['adj_matrix']\n","          feat = torch.tensor(feat.tolist().toarray()).float()\n","          labels = torch.tensor(labels)\n","          labels = labels.to(torch.int64)\n","          labels = labels - 1\n","          adj_matrix = adj_matrix.tolist().toarray()\n","          adj_matrix = adj_matrix + np.transpose(adj_matrix) + np.eye(adj_matrix.shape[0])\n","          print(adj_matrix)\n","          src, dst = np.nonzero(adj_matrix)\n","\n","          self.graph = dgl.graph(\n","            (src, dst), num_nodes=adj_matrix.shape[0]\n","            )\n","          self.graph.ndata[\"feat\"] = feat\n","          self.graph.ndata[\"label\"] = labels\n","          self.num_classes = len(np.unique(labels))\n","          print(\"Loading done\")\n","\n","    def __getitem__(self, i):\n","        return self.graph\n","\n","    def __len__(self):\n","        return 1\n","\n","\n","class DBLP(DGLDataset):\n","    def __init__(self):\n","        super().__init__(name=\"DBLP\")\n","\n","    def process(self):\n","          print(\"Loading DBLP graph dataset...\")\n","          data = np.load('DBLP_BERT_graph_data.npz', allow_pickle=True)\n","          labels = data['labels']\n","          feat = data['feature_matrix']\n","          adj_matrix =  data['adj_mat']\n","\n","          feat = torch.tensor(feat).float()\n","          labels = torch.tensor(labels)\n","          labels = labels.to(torch.int64)\n","          adj_matrix = adj_matrix.tolist().toarray()\n","          adj_matrix = adj_matrix + np.transpose(adj_matrix) + np.eye(adj_matrix.shape[0])\n","          print(adj_matrix)\n","          src, dst = np.nonzero(adj_matrix)\n","\n","          self.graph = dgl.graph(\n","            (src, dst), num_nodes=adj_matrix.shape[0]\n","            )\n","          self.graph.ndata[\"feat\"] = feat\n","          self.graph.ndata[\"label\"] = labels\n","          self.num_classes = len(np.unique(labels))\n","          print(\"Loading done\")\n","\n","    def __getitem__(self, i):\n","        return self.graph\n","\n","    def __len__(self):\n","        return 1"],"metadata":{"id":"HQsH0RXX9g_2","executionInfo":{"status":"ok","timestamp":1715459793570,"user_tz":240,"elapsed":1257,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a8b6dc6-b34c-447a-9733-4dcc38212035"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5sjmKexguv3"},"outputs":[],"source":["import numpy as np\n","import scipy.sparse as sp\n","import torch\n","import sys\n","import pickle as pkl\n","import networkx as nx\n","from time import perf_counter\n","\n","\n","import dgl\n","from dgl.data import CoauthorCSDataset, CoauthorPhysicsDataset\n","import torch.sparse as sp\n","import dgl.function as fn\n","\n","from dgl import AddSelfLoop\n","import dgl.sparse as dglsp\n","\n","\n","def parse_index_file(filename):\n","    \"\"\"Parse index file.\"\"\"\n","    index = []\n","    for line in open(filename):\n","        index.append(int(line.strip()))\n","    return index\n","\n","def preprocess_citation(adj, features, normalization=\"FirstOrderGCN\"):\n","    adj_normalizer = fetch_normalization(normalization)\n","    adj = adj_normalizer(adj)\n","    features = row_normalize(features)\n","    return adj, features\n","\n","def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n","    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n","    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n","    indices = torch.from_numpy(\n","        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n","    values = torch.from_numpy(sparse_mx.data)\n","    shape = torch.Size(sparse_mx.shape)\n","    return torch.sparse.FloatTensor(indices, values, shape)\n","\n","def load_citation(dataset_str=\"cora\", normalization=\"AugNormAdj\", cuda=True):\n","    \"\"\"\n","    Load Citation Networks Datasets.\n","    \"\"\"\n","\n","    if dataset_str == 'CS' or dataset_str == 'Physics' or dataset_str == 'BlogCatalog' or dataset_str == 'DBLP':\n","      if dataset_str == 'CS':\n","        dataset = CoauthorCSDataset(transform= AddSelfLoop())\n","      if dataset_str == 'Physics':\n","        dataset = CoauthorPhysicsDataset(transform= AddSelfLoop())\n","      if dataset_str == 'BlogCatalog':\n","        dataset = Blogcatalog()\n","      if dataset_str == 'DBLP':\n","        dataset = DBLP()\n","      num_classes = dataset.num_classes\n","      g = dataset[0]\n","      degs = g.in_degrees().float()\n","      norm = torch.pow(degs, -0.5)\n","      norm[torch.isinf(norm)] = 0\n","      g.ndata['norm'] = norm.unsqueeze(1)\n","      g.apply_edges(fn.u_mul_v('norm', 'norm', 'normalized'))\n","\n","      features = g.ndata['feat']\n","      labels = g.ndata['label']\n","      train_node_ids, val_node_ids, test_node_ids = split_train_val_test_ids(g.ndata['label'].numpy())\n","\n","      train_mask = np.zeros(g.num_nodes(), dtype=bool)\n","      train_mask[train_node_ids] = True\n","\n","      val_mask = np.zeros(g.num_nodes(), dtype=bool)\n","      val_mask[val_node_ids] = True\n","\n","      test_mask = np.zeros(g.num_nodes(), dtype=bool)\n","      test_mask[test_node_ids] = True\n","\n","      train_mask = torch.from_numpy(train_mask)\n","      val_mask = torch.from_numpy(val_mask)\n","      test_mask = torch.from_numpy(test_mask)\n","\n","      num_nodes = g.number_of_nodes()\n","      adj = g.adj()\n","      indices = adj.indices()\n","      values = torch.squeeze(g.edata['normalized'])\n","      shape = adj.shape\n","\n","      adj = torch.sparse_coo_tensor(indices, values, shape)\n","\n","      idx_train = torch.nonzero(train_mask).flatten()\n","      idx_val = torch.nonzero(val_mask).flatten()\n","      idx_test = torch.nonzero(test_mask).flatten()\n","      return adj, features, labels, idx_train, idx_val, idx_test\n","\n","\n","    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n","    objects = []\n","    for i in range(len(names)):\n","        with open(\"data/ind.{}.{}\".format(dataset_str.lower(), names[i]), 'rb') as f:\n","            if sys.version_info > (3, 0):\n","                objects.append(pkl.load(f, encoding='latin1'))\n","            else:\n","                objects.append(pkl.load(f))\n","\n","    x, y, tx, ty, allx, ally, graph = tuple(objects)\n","    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset_str))\n","    test_idx_range = np.sort(test_idx_reorder)\n","\n","    if dataset_str == 'citeseer':\n","        # Fix citeseer dataset (there are some isolated nodes in the graph)\n","        # Find isolated nodes, add them as zero-vecs into the right position\n","        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n","        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n","        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n","        tx = tx_extended\n","        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n","        ty_extended[test_idx_range-min(test_idx_range), :] = ty\n","        ty = ty_extended\n","\n","    features = sp.vstack((allx, tx)).tolil()\n","    features[test_idx_reorder, :] = features[test_idx_range, :]\n","    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n","    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n","    labels = np.vstack((ally, ty))\n","    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n","\n","    idx_test = test_idx_range.tolist()\n","    idx_train = range(len(y))\n","    idx_val = range(len(y), len(y)+500)\n","\n","    adj, features = preprocess_citation(adj, features, normalization)\n","\n","    # porting to pytorch\n","    features = torch.FloatTensor(np.array(features.todense())).float()\n","    labels = torch.LongTensor(labels)\n","    labels = torch.max(labels, dim=1)[1]\n","    adj = sparse_mx_to_torch_sparse_tensor(adj).float()\n","    idx_train = torch.LongTensor(idx_train)\n","    idx_val = torch.LongTensor(idx_val)\n","    idx_test = torch.LongTensor(idx_test)\n","\n","    if cuda:\n","        features = features.cuda()\n","        adj = adj.cuda()\n","        labels = labels.cuda()\n","        idx_train = idx_train.cuda()\n","        idx_val = idx_val.cuda()\n","        idx_test = idx_test.cuda()\n","\n","    return adj, features, labels, idx_train, idx_val, idx_test\n","\n","def sgc_precompute(features, adj, degree):\n","    for i in range(degree):\n","        features = torch.spmm(adj, features)\n","    return features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6SnEMUhYggFK"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import Module\n","import torch.nn.functional as F\n","import math\n","\n","class SGC(nn.Module):\n","    \"\"\"\n","    A Simple PyTorch Implementation of Logistic Regression.\n","    Assuming the features have been preprocessed with k-step graph propagation.\n","    \"\"\"\n","    def __init__(self, nfeat, nclass):\n","        super(SGC, self).__init__()\n","\n","        self.W = nn.Linear(nfeat, nclass)\n","\n","    def forward(self, x):\n","        return self.W(x)\n","\n","def get_model(model_opt, nfeat, nclass, nhid=0, dropout=0, cuda=True):\n","    if model_opt == \"SGC\":\n","        model = SGC(nfeat=nfeat,\n","                    nclass=nclass)\n","    else:\n","        raise NotImplementedError('model:{} is not implemented!'.format(model_opt))\n","\n","    if cuda: model.cuda()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQV6zY6cgk60"},"outputs":[],"source":["import numpy as np\n","import scipy.sparse as sp\n","import torch\n","\n","def aug_normalized_adjacency(adj):\n","   adj = adj + sp.eye(adj.shape[0])\n","   adj = sp.coo_matrix(adj)\n","   row_sum = np.array(adj.sum(1))\n","   d_inv_sqrt = np.power(row_sum, -0.5).flatten()\n","   d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n","   d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n","   return d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt).tocoo()\n","\n","def fetch_normalization(type):\n","   switcher = {\n","       'AugNormAdj': aug_normalized_adjacency,  # A' = (D + I)^-1/2 * ( A + I ) * (D + I)^-1/2\n","   }\n","   func = switcher.get(type, lambda: \"Invalid normalization technique.\")\n","   return func\n","\n","def row_normalize(mx):\n","    \"\"\"Row-normalize sparse matrix\"\"\"\n","    rowsum = np.array(mx.sum(1))\n","    r_inv = np.power(rowsum, -1).flatten()\n","    r_inv[np.isinf(r_inv)] = 0.\n","    r_mat_inv = sp.diags(r_inv)\n","    mx = r_mat_inv.dot(mx)\n","    return mx\n","\n","def accuracy(output, labels):\n","    preds = output.max(1)[1].type_as(labels)\n","    correct = preds.eq(labels).double()\n","    correct = correct.sum()\n","    return correct / len(labels)"]},{"cell_type":"code","source":["# Arguments\n","\n","\n","args = get_citation_args()\n","\n","def train_regression(model,\n","                     train_features, train_labels,\n","                     val_features, val_labels,\n","                     epochs=args.epochs, weight_decay=args.weight_decay,\n","                     lr=args.lr, dropout=args.dropout):\n","\n","    t = perf_counter()\n","    optimizer = optim.Adam(model.parameters(), lr=lr,\n","                           weight_decay=weight_decay)\n","\n","    best_val_loss = float('inf')\n","    current_patience = 0\n","    if lr == 0.01:\n","        patience = 25\n","        min_delta = 0.0001\n","    elif lr == 0.001:\n","        patience = 50\n","        min_delta = 0.0001\n","    min_delta = 0.01\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        output = model(train_features)\n","        loss_train = F.cross_entropy(output, train_labels)\n","        loss_train.backward()\n","        optimizer.step()\n","\n","        with torch.no_grad():\n","          model.eval()\n","          output = model(val_features)\n","          loss_val = F.cross_entropy(output, val_labels)\n","          acc_val = accuracy(output, val_labels)\n","\n","        #My additon for early stopping\n","        curr_val_loss = loss_val.item()\n","\n","        # Early stopping check\n","        if best_val_loss - curr_val_loss > min_delta:\n","          best_val_loss = curr_val_loss\n","          current_patience = 0\n","        else:\n","          current_patience += 1\n","\n","        if current_patience > patience:\n","          print(f'Early stopping at epoch {epoch}')\n","          break\n","    train_time = perf_counter()-t\n","\n","\n","\n","\n","    return model, acc_val, train_time\n","\n","def test_regression(model, test_features, test_labels):\n","    model.eval()\n","    return accuracy(model(test_features), test_labels)"],"metadata":{"id":"4_T4qo5beljL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6355,"status":"ok","timestamp":1715459984020,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"},"user_tz":240},"id":"Egj1AqQ7gphZ","outputId":"2056f153-8f1f-41e0-c533-ba1f0a47f6db"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-5f1e8256ba25>:99: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n","  objects.append(pkl.load(f, encoding='latin1'))\n"]},{"output_type":"stream","name":"stdout","text":["\r  0%|          | 0/12 [00:00<?, ?trial/s, best loss=?]"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-5f1e8256ba25>:39: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:618.)\n","  return torch.sparse.FloatTensor(indices, values, shape)\n"]},{"output_type":"stream","name":"stdout","text":["Early stopping at epoch 384\n","lr: 1.00e-02 weight decay: 1.00e-05 accuracy: 0.7840\n","Early stopping at epoch 117\n","lr: 1.00e-02 weight decay: 1.00e-03 accuracy: 0.7780\n","Early stopping at epoch 405\n","lr: 1.00e-02 weight decay: 5.00e-06 accuracy: 0.7800\n","Early stopping at epoch 103\n","lr: 1.00e-02 weight decay: 1.00e-03 accuracy: 0.7720\n","Early stopping at epoch 286\n","lr: 1.00e-02 weight decay: 1.00e-04 accuracy: 0.7760\n","Early stopping at epoch 153\n","lr: 1.00e-02 weight decay: 5.00e-04 accuracy: 0.7760\n","Early stopping at epoch 411\n","lr: 1.00e-02 weight decay: 5.00e-06 accuracy: 0.7820\n","Early stopping at epoch 171\n","lr: 1.00e-03 weight decay: 1.00e-03 accuracy: 0.7400\n","Early stopping at epoch 117\n","lr: 1.00e-02 weight decay: 1.00e-03 accuracy: 0.7780\n","Early stopping at epoch 153\n","lr: 1.00e-02 weight decay: 5.00e-04 accuracy: 0.7760\n","Early stopping at epoch 392\n","lr: 1.00e-02 weight decay: 5.00e-06 accuracy: 0.7780\n","Early stopping at epoch 51\n","lr: 1.00e-03 weight decay: 5.00e-04 accuracy: 0.7200\n","100%|██████████| 12/12 [00:05<00:00,  2.27trial/s, best loss: -0.784]\n","Best lr: 1.00e-02Best weight decay: 1.00e-05\n","Time elapsed for Hyper-parmeter search:  5.29043436050415  seconds\n","{'lr': 1, 'weight_decay': 4}\n"]}],"source":["import time\n","import argparse\n","import numpy as np\n","import pickle as pkl\n","import os\n","from math import log\n","import torch\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","import torch.optim as optim\n","\n","\n","space = {'weight_decay' : hp.choice('weight_decay', (0.001, 0.0005, 0.0001, 0.00005 ,0.00001, 0.000005)), 'lr' : hp.choice('lr', (0.001, 0.01))}\n","lr_list = [0.001, 0.01]\n","weight_decay_list = [0.001, 0.0005, 0.0001, 0.00005 ,0.00001, 0.000005]\n","\n","adj, features, labels, idx_train, idx_val, idx_test = load_citation(args.dataset, args.normalization, args.cuda)\n","\n","def sgc_objective(space):\n","    model = get_model(args.model, features.size(1), labels.max().item()+1, args.hidden, args.dropout, args.cuda)\n","    features1 = sgc_precompute(features, adj, args.degree)\n","    model, acc_val, _ = train_regression(model, features1[idx_train], labels[idx_train], features1[idx_val], labels[idx_val],\n","                                      args.epochs, space['weight_decay'], space['lr'], args.dropout)\n","    print('lr: {:.2e} '.format(space['lr']) + 'weight decay: {:.2e} '.format(space['weight_decay']) + 'accuracy: {:.4f}'.format(acc_val))\n","    return {'loss': -acc_val, 'status': STATUS_OK}\n","\n","\n","t_start_tune = time.time()\n","best = fmin(sgc_objective, space=space, algo=tpe.suggest, max_evals=12)\n","\n","t_end_tune = time.time()\n","print(\"Best lr: {:.2e}\".format(lr_list[best[\"lr\"]]) + \"Best weight decay: {:.2e}\".format(weight_decay_list[best[\"weight_decay\"]]))\n","\n","print(\"Time elapsed for Hyper-parmeter search: \", t_end_tune-t_start_tune, \" seconds\")\n","\n","print(best)\n","\n","os.makedirs(\"./{}-tuning\".format(args.model), exist_ok=True)\n","path = '{}-tuning/{}.txt'.format(args.model, args.dataset)\n","with open(path, 'wb') as f: pkl.dump(best, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_VnHfRbWgZQd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714002486486,"user_tz":240,"elapsed":868,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}},"outputId":"46b49dd8-d033-41b9-a666-927bea5291a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["using tuned weight decay: 1e-05\n","Early stopping at epoch 383\n","Validation Accuracy: 0.7840 Test Accuracy: 0.7620\n","Time Elpased: 0.5319s\n"]}],"source":["import time\n","import argparse\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","\n","import pickle as pkl\n","import time\n","\n","\n","if True:\n","# if args.tuned:\n","    if args.model == \"SGC\":\n","        with open(\"{}-tuning/{}.txt\".format(args.model, args.dataset), 'rb') as f:\n","            params = pkl.load(f)\n","            args.lr = lr_list[params['lr']]\n","            args.weight_decay = weight_decay_list[params['weight_decay']]\n","            print(\"using tuned weight decay: {}\".format(args.weight_decay))\n","    else:\n","        raise NotImplemented\n","\n","model = get_model(args.model, features.size(1), labels.max().item()+1, args.hidden, args.dropout, args.cuda)\n","\n","\n","\n","if args.model == \"SGC\":\n","    start_time = time.time()\n","    features = sgc_precompute(features, adj, args.degree)\n","    model, acc_val, train_time = train_regression(model, features[idx_train], labels[idx_train], features[idx_val], labels[idx_val],\n","                     args.epochs, args.weight_decay, args.lr, args.dropout)\n","    acc_test = test_regression(model, features[idx_test], labels[idx_test])\n","    end_time = time.time()\n","    total_time_elapsed = end_time - start_time\n","\n","print(\"Validation Accuracy: {:.4f} Test Accuracy: {:.4f}\".format(acc_val, acc_test))\n","print(\"Time Elpased: {:.4f}s\".format(total_time_elapsed))"]},{"cell_type":"code","source":[],"metadata":{"id":"3N7fztDdgl73"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNPFF7aCCEzkHneMj1g4Yj6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}